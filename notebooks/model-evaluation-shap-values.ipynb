{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MODEL EVALUATION NOTEBOOK"},{"metadata":{},"cell_type":"markdown","source":"In this notebook we'll use several tools to visualize the inner working of our GBM models, how & why they make their predictions.\nFor this we'll use feature importances visualization and the package shap that allow us to access many very useful viz."},{"metadata":{},"cell_type":"markdown","source":"### What are shapley values ?"},{"metadata":{},"cell_type":"markdown","source":"Shapley values were conceived to try and answer a theoretical game theory question \"how can we find each player's marginal contribution, averaged over every possible sequence in which the players could have been added to the group ?\" /\nIn our context of evaluating our model features importances, we can see that shapley values can be a very valuable asset to understand each feature marginal effect on our model predictions."},{"metadata":{},"cell_type":"markdown","source":"The equation they find to evaluate this effect satisfies three axioms of credit-attribution : \n* If a player never adds any marginal value, their payoff portion should be 0 (Dummy player)\n* If two players always add the same marginal value to any subset to which they're added, their payoff portion should be the same (Substitutability)\n* If a game is composed of two subgames, you should be able to add the payoffs calculated on the subgames and it should match the payoff of the full game (Additivity)"},{"metadata":{},"cell_type":"markdown","source":"## IMPORTS"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, joblib\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport lightgbm as lgb\nimport shap\nimport matplotlib.pylab as pl\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## UTILS"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nfrom sklearn.preprocessing import LabelEncoder \n\ndef cat_encoding(dataframe):\n    cat = dataframe.columns[1:20]\n    for feature in cat:\n        le = LabelEncoder()\n        le.fit(dataframe[feature])\n        dataframe[feature] = le.transform(dataframe[feature])\n    return dataframe\n\ndef feature_engineering(dataframe):\n    dataframe = cat_encoding(dataframe)\n    features = dataframe.columns[1:31]\n    return dataframe, features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CONFIG"},{"metadata":{"trusted":true},"cell_type":"code","source":"config = {\n    \"MODEL_PATH\" : \"D:/Documents/GitHub/gbm_pipeline/task/TPS-MAR2021/model_saved/XGB_CL_model_1.joblib.dat\",\n    \"TRAIN_PATH\" : \"../input/tabular-playground-series-mar-2021/train.csv\",\n    \"TEST_PATH\" : \"../input/tabular-playground-series-mar-2021/test.csv\",\n    \"TARGET_VAR\" : \"target\"\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LOADING DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(config[\"TRAIN_PATH\"])\ndf_test = pd.read_csv(config[\"TEST_PATH\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, features_train = feature_engineering(df_train)\ndf_test, features_test = feature_engineering(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_train = df_train[config[\"TARGET_VAR\"]].values\ndf_train = df_train[features_train]\ntrain_x, valid_x, train_y, valid_y = train_test_split(df_train, target_train, test_size=0.2, random_state=95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = xgb.DMatrix(train_x, label=train_y)\nvalid = xgb.DMatrix(valid_x, label=valid_y)\ntest = xgb.DMatrix(df_test[features_test])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TRAINING A MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    \"objective\": \"binary:logistic\",\n    \"eval_metric\" : \"auc\",\n    \"seed\": 95,\n    'tree_method': \"gpu_hist\",\n    'predictor': 'gpu_predictor',\n    \"use_label_encoder\" : False,\n    \"n_estimators\" : 100000,\n    'max_bin' : 64,\n    \"max_depth\": 12, #Max should correspond to max number of features (probably ?),\n    'alpha' : 11.607239831188968,\n    'gamma' : 2.1593805822598444,\n    \"learning_rate\": 0.02,\n    \"colsample_bytree\": 0.8016656211574054,\n    \"subsample\": 0.983461992112787,\n    \"reg_alpha\" : 1.7306711078859136,\n    \"min_child_weight\": 9.417969426623086,\n    \"n_jobs\": 2\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = xgb.train(params, train, 400)\n#valid_oof = model.predict(valid)\n#temp_test = model.predict(test)\n#auc = roc_auc_score(valid_y, valid_oof)\n#print('AUC score %.6f' % auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FITTING A MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.XGBClassifier(**params)\nmodel.fit(\n    train_x, \n    train_y, \n    eval_set=[(valid_x, valid_y)], \n    early_stopping_rounds=200, \n    verbose = 1000\n)\nvalid_oof = model.predict(valid_x)\ntemp_test = model.predict(df_test[features_test])\nauc = roc_auc_score(valid_y, valid_oof)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('AUC score %.6f' % auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGB boost plot tools"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.plot_importance(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SHAP"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer(valid_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nshap.plots.beeswarm(shap_values, max_display=35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.plots.bar(shap_values, max_display=35)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## VIZ INDIVIDUAL DATA PREDS"},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.plots.waterfall(shap_values[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.plots.force(shap_values[0])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}